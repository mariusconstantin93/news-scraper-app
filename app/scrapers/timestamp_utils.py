#!/usr/bin/env python3
"""
UtilitÄƒÈ›i pentru extragerea È™i gestionarea timestamp-urilor din sursele de È™tiri
La ora RomÃ¢niei (Europe/Bucharest)
"""

import re
import requests
from datetime import datetime, timezone
import pytz
from dateutil import parser
from bs4 import BeautifulSoup

# Timezone RomÃ¢nia
ROMANIA_TZ = pytz.timezone('Europe/Bucharest')

def get_romania_now():
    """ReturneazÄƒ timestamp-ul curent la ora RomÃ¢niei"""
    return datetime.now(ROMANIA_TZ)

def parse_to_romania_time(date_string, source_format=None):
    """
    ConverteÈ™te un string de datÄƒ la timezone RomÃ¢nia
    
    Args:
        date_string: String cu data (ex: "2025-06-29T15:03:11Z" sau "28.06.2025 11:24")
        source_format: Format opÈ›ional pentru parsing specific
    
    Returns:
        datetime cu timezone RomÃ¢nia sau None dacÄƒ parsing-ul eÈ™ueazÄƒ
    """
    if not date_string:
        return None
    
    try:
        # ÃncearcÄƒ sÄƒ parse date-ul
        if source_format:
            # FoloseÈ™te format specific
            dt = datetime.strptime(date_string.strip(), source_format)
            # Presupune cÄƒ e Ã®n timezone RomÃ¢nia dacÄƒ nu e specificat altfel
            if dt.tzinfo is None:
                dt = ROMANIA_TZ.localize(dt)
        else:
            # Auto-detect format
            dt = parser.parse(date_string.strip())
            
            # DacÄƒ nu are timezone, presupune RomÃ¢nia
            if dt.tzinfo is None:
                dt = ROMANIA_TZ.localize(dt)
            else:
                # ConverteÈ™te la timezone RomÃ¢nia
                dt = dt.astimezone(ROMANIA_TZ)
        
        return dt
        
    except Exception as e:
        print(f"âš ï¸  Eroare parsing datÄƒ '{date_string}': {e}")
        return None

def extract_adevarul_published_date(article_url):
    """
    Extrage data publicÄƒrii de pe un articol Adevarul.ro
    
    CautÄƒ pattern-uri precum:
    - "Publicat: 28.06.2025 11:24 Ultima actualizare: 28.06.2025 11:35"
    - Meta tags cu data
    - JSON-LD schema
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Strategia 1: CautÄƒ pattern "Publicat: DD.MM.YYYY HH:MM"
        published_patterns = [
            r'Publicat:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})',
            r'Publicat\s*:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})',
            r'(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})'
        ]
        
        article_text = soup.get_text()
        for pattern in published_patterns:
            match = re.search(pattern, article_text)
            if match:
                date_str = match.group(1)
                # ConverteÈ™te formatul DD.MM.YYYY HH:MM
                try:
                    dt = datetime.strptime(date_str, '%d.%m.%Y %H:%M')
                    return ROMANIA_TZ.localize(dt)
                except:
                    continue
        
        # Strategia 2: Meta tags
        meta_selectors = [
            'meta[property="article:published_time"]',
            'meta[name="publish-date"]',
            'meta[name="date"]',
            'meta[property="og:published_time"]'
        ]
        
        for selector in meta_selectors:
            meta_tag = soup.select_one(selector)
            if meta_tag:
                content = meta_tag.get('content', '')
                if content:
                    parsed_date = parse_to_romania_time(content)
                    if parsed_date:
                        return parsed_date
        
        # Strategia 3: JSON-LD schema
        json_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_scripts:
            try:
                import json
                data = json.loads(script.string)
                if isinstance(data, dict):
                    # CautÄƒ datePublished
                    if 'datePublished' in data:
                        parsed_date = parse_to_romania_time(data['datePublished'])
                        if parsed_date:
                            return parsed_date
                    # CautÄƒ Ã®n array de obiecte
                    elif isinstance(data, list):
                        for item in data:
                            if isinstance(item, dict) and 'datePublished' in item:
                                parsed_date = parse_to_romania_time(item['datePublished'])
                                if parsed_date:
                                    return parsed_date
            except:
                continue
        
        # Strategia 4: Time elements
        time_elements = soup.find_all('time')
        for time_elem in time_elements:
            datetime_attr = time_elem.get('datetime', '')
            if datetime_attr:
                parsed_date = parse_to_romania_time(datetime_attr)
                if parsed_date:
                    return parsed_date
        
        print(f"âš ï¸  Nu s-a gÄƒsit data publicÄƒrii pentru {article_url}")
        return None
        
    except Exception as e:
        print(f"âŒ Eroare extragere datÄƒ Adevarul {article_url}: {e}")
        return None

def extract_biziday_published_date(article_url):
    """
    Extrage data publicÄƒrii de pe un articol Biziday.ro
    
    CautÄƒ meta-tag-uri precum:
    - <time class="timeago" datetime="2025-06-29T15:03:11Z" title="2025-06-29 @ 14:56:26">
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Strategia 1: <time class="timeago" datetime="...">
        time_elements = soup.find_all('time', class_='timeago')
        for time_elem in time_elements:
            datetime_attr = time_elem.get('datetime', '')
            if datetime_attr:
                # Format: "2025-06-29T15:03:11Z"
                parsed_date = parse_to_romania_time(datetime_attr)
                if parsed_date:
                    return parsed_date
        
        # Strategia 2: Orice element time cu datetime
        time_elements = soup.find_all('time')
        for time_elem in time_elements:
            datetime_attr = time_elem.get('datetime', '')
            if datetime_attr:
                parsed_date = parse_to_romania_time(datetime_attr)
                if parsed_date:
                    return parsed_date
        
        # Strategia 3: Meta tags
        meta_selectors = [
            'meta[property="article:published_time"]',
            'meta[name="publish-date"]',
            'meta[name="date"]'
        ]
        
        for selector in meta_selectors:
            meta_tag = soup.select_one(selector)
            if meta_tag:
                content = meta_tag.get('content', '')
                if content:
                    parsed_date = parse_to_romania_time(content)
                    if parsed_date:
                        return parsed_date
        
        print(f"âš ï¸  Nu s-a gÄƒsit data publicÄƒrii pentru {article_url}")
        return None
        
    except Exception as e:
        print(f"âŒ Eroare extragere datÄƒ Biziday {article_url}: {e}")
        return None

def extract_rss_published_date(rss_entry):
    """
    Extrage data publicÄƒrii dintr-un entry RSS
    
    Args:
        rss_entry: Entry din feed RSS cu cÃ¢mpuri published_parsed sau published
    """
    try:
        # ÃncearcÄƒ published_parsed (tuple time)
        if hasattr(rss_entry, 'published_parsed') and rss_entry.published_parsed:
            import time
            timestamp = time.mktime(rss_entry.published_parsed)
            dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
            return dt.astimezone(ROMANIA_TZ)
        
        # ÃncearcÄƒ published (string)
        if hasattr(rss_entry, 'published') and rss_entry.published:
            parsed_date = parse_to_romania_time(rss_entry.published)
            if parsed_date:
                return parsed_date
        
        # ÃncearcÄƒ updated
        if hasattr(rss_entry, 'updated') and rss_entry.updated:
            parsed_date = parse_to_romania_time(rss_entry.updated)
            if parsed_date:
                return parsed_date
        
        return None
        
    except Exception as e:
        print(f"âš ï¸  Eroare parsing datÄƒ RSS: {e}")
        return None

def format_for_database(dt):
    """
    FormateazÄƒ datetime pentru salvare Ã®n PostgreSQL cu timezone
    
    Args:
        dt: datetime object cu timezone
        
    Returns:
        string formatat pentru PostgreSQL sau None
    """
    if not dt:
        return None
    
    # AsigurÄƒ-te cÄƒ are timezone
    if dt.tzinfo is None:
        dt = ROMANIA_TZ.localize(dt)
    
    # ConverteÈ™te la timezone RomÃ¢nia
    dt_ro = dt.astimezone(ROMANIA_TZ)
    
    # Format PostgreSQL: YYYY-MM-DD HH:MM:SS+TZ
    return dt_ro.isoformat()

def extract_published_date_from_content(url, source_name="unknown"):
    """
    Extrage data publicÄƒrii dintr-un URL specific Ã®n funcÈ›ie de sursa de È™tiri
    
    Args:
        url: URL-ul articolului
        source_name: Numele sursei ("adevarul", "biziday", etc.)
        
    Returns:
        datetime cu timezone RomÃ¢nia sau None
    """
    source_name = source_name.lower()
    
    if 'adevarul' in source_name or 'adevarul.ro' in url:
        return extract_adevarul_published_date(url)
    elif 'biziday' in source_name or 'biziday.ro' in url:
        return extract_biziday_published_date(url)
    else:
        # Ãncercare genericÄƒ
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # CautÄƒ meta tags generale
            meta_selectors = [
                'meta[property="article:published_time"]',
                'meta[name="publish-date"]',
                'meta[name="date"]',
                'meta[property="og:published_time"]'
            ]
            
            for selector in meta_selectors:
                meta_tag = soup.select_one(selector)
                if meta_tag:
                    content = meta_tag.get('content', '')
                    if content:
                        parsed_date = parse_to_romania_time(content)
                        if parsed_date:
                            return parsed_date
            
            # CautÄƒ time elements
            time_elements = soup.find_all('time')
            for time_elem in time_elements:
                datetime_attr = time_elem.get('datetime', '')
                if datetime_attr:
                    parsed_date = parse_to_romania_time(datetime_attr)
                    if parsed_date:
                        return parsed_date
            
            return None
            
        except Exception as e:
            print(f"âŒ Eroare extragere datÄƒ genericÄƒ {url}: {e}")
            return None

def extract_adevarul_updated_date(article_url):
    """
    Extrage data actualizÄƒrii de pe un articol Adevarul.ro (OPTIMIZATÄ‚)
    
    CautÄƒ pattern-uri precum:
    - "Ultima actualizare: 28.06.2025 11:35"
    - JSON-LD cu "dateModified"
    - Meta tags cu data modificÄƒrii
    
    Returns:
        datetime cu timezone RomÃ¢nia sau None dacÄƒ nu e disponibilÄƒ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(article_url, headers=headers, timeout=5)  # Timeout redus la 5s
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Strategia 1: JSON-LD schema cu dateModified (cea mai rapidÄƒ)
        json_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_scripts[:3]:  # Limitez la primele 3 script-uri
            try:
                import json
                data = json.loads(script.string)
                
                # FuncÈ›ie helper pentru a cÄƒuta Ã®n structuri nested
                def find_date_modified(obj, depth=0):
                    if depth > 3:  # Limitez depth-ul pentru performanÈ›Äƒ
                        return None
                    if isinstance(obj, dict):
                        if 'dateModified' in obj:
                            return obj['dateModified']
                        # CautÄƒ doar Ã®n cÃ¢mpurile importante
                        for key in ['@graph', 'mainEntity', 'article']:
                            if key in obj:
                                result = find_date_modified(obj[key], depth + 1)
                                if result:
                                    return result
                    elif isinstance(obj, list) and len(obj) < 10:  # Limitez list-urile mari
                        for item in obj:
                            result = find_date_modified(item, depth + 1)
                            if result:
                                return result
                    return None
                
                date_modified = find_date_modified(data)
                if date_modified:
                    parsed_date = parse_to_romania_time(date_modified)
                    if parsed_date:
                        return parsed_date
                        
            except:
                continue
        
        # Strategia 2: CautÄƒ pattern "Ultima actualizare" doar Ã®n primele 500 caractere
        article_text = soup.get_text()[:500]  # Limitez textul pentru cÄƒutare rapidÄƒ
        updated_patterns = [
            r'Ultima actualizare:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})',
            r'Actualizat:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})'
        ]
        
        for pattern in updated_patterns:
            match = re.search(pattern, article_text)
            if match:
                date_str = match.group(1)
                try:
                    dt = datetime.strptime(date_str, '%d.%m.%Y %H:%M')
                    return ROMANIA_TZ.localize(dt)
                except:
                    continue
        
        # Strategia 3: Meta tags (rapid)
        meta_tag = soup.select_one('meta[property="article:modified_time"]')
        if meta_tag:
            content = meta_tag.get('content', '')
            if content:
                parsed_date = parse_to_romania_time(content)
                if parsed_date:
                    return parsed_date
        
        return None  # Nu s-a gÄƒsit data actualizÄƒrii
        
    except Exception as e:
        # Timeout sau eroare de reÈ›ea - returneazÄƒ None rapid
        return None
    """
    Extrage data actualizÄƒrii de pe un articol Adevarul.ro
    
    CautÄƒ pattern-uri precum:
    - JSON-LD cu "dateModified" (prioritate)
    - "Ultima actualizare: 28.06.2025 11:35"
    - Meta tags cu data modificÄƒrii
    
    Returns:
        datetime cu timezone RomÃ¢nia sau None dacÄƒ nu e disponibilÄƒ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Strategia 1 (PRIORITATE): JSON-LD schema cu dateModified
        json_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_scripts:
            try:
                import json
                data = json.loads(script.string)
                
                # FuncÈ›ie helper pentru a cÄƒuta Ã®n structuri nested
                def find_date_modified(obj):
                    if isinstance(obj, dict):
                        if 'dateModified' in obj:
                            return obj['dateModified']
                        for value in obj.values():
                            result = find_date_modified(value)
                            if result:
                                return result
                    elif isinstance(obj, list):
                        for item in obj:
                            result = find_date_modified(item)
                            if result:
                                return result
                    return None
                
                date_modified = find_date_modified(data)
                if date_modified:
                    parsed_date = parse_to_romania_time(date_modified)
                    if parsed_date:
                        return parsed_date
                        
            except:
                continue
        
        # Strategia 2: CautÄƒ pattern "Ultima actualizare: DD.MM.YYYY HH:MM"
        updated_patterns = [
            r'Ultima actualizare:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})',
            r'Ultima\s+actualizare\s*:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})',
            r'Actualizat:\s*(\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})'
        ]
        
        article_text = soup.get_text()
        for pattern in updated_patterns:
            match = re.search(pattern, article_text)
            if match:
                date_str = match.group(1)
                # ConverteÈ™te formatul DD.MM.YYYY HH:MM
                try:
                    dt = datetime.strptime(date_str, '%d.%m.%Y %H:%M')
                    return ROMANIA_TZ.localize(dt)
                except:
                    continue
        
        # Strategia 3: Meta tags pentru datÄƒ modificare
        meta_selectors = [
            'meta[property="article:modified_time"]',
            'meta[name="last-modified"]',
            'meta[name="modified-date"]',
            'meta[property="og:updated_time"]'
        ]
        
        for selector in meta_selectors:
            meta_tag = soup.select_one(selector)
            if meta_tag:
                content = meta_tag.get('content', '')
                if content:
                    parsed_date = parse_to_romania_time(content)
                    if parsed_date:
                        return parsed_date
        
        # Nu s-a gÄƒsit nicio datÄƒ de actualizare - returneazÄƒ None
        print(f"âš ï¸  Nu s-a gÄƒsit data actualizÄƒrii pentru {article_url}")
        return None
        
    except Exception as e:
        print(f"âŒ Eroare extragere datÄƒ actualizare Adevarul {article_url}: {e}")
        return None

def extract_biziday_updated_date(article_url):
    """
    Extrage data actualizÄƒrii de pe un articol Biziday.ro
    
    CautÄƒ meta-tag-uri precum:
    - <meta property="article:modified_time" content="2025-06-29T15:05:11Z"> (PRIORITATE)
    - Alte meta tags cu data modificÄƒrii
    - JSON-LD cu dateModified
    
    Returns:
        datetime cu timezone RomÃ¢nia sau None dacÄƒ nu e disponibilÄƒ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Strategia 1 (PRIORITATE): Meta tag article:modified_time
        meta_modified = soup.find('meta', property='article:modified_time')
        if meta_modified:
            content = meta_modified.get('content', '')
            if content:
                parsed_date = parse_to_romania_time(content)
                if parsed_date:
                    return parsed_date
        
        # Strategia 2: Alte meta tags pentru datÄƒ modificare
        meta_selectors = [
            'meta[name="last-modified"]',
            'meta[name="modified-date"]',
            'meta[property="og:updated_time"]',
            'meta[name="date.updated"]'
        ]
        
        for selector in meta_selectors:
            meta_tag = soup.select_one(selector)
            if meta_tag:
                content = meta_tag.get('content', '')
                if content:
                    parsed_date = parse_to_romania_time(content)
                    if parsed_date:
                        return parsed_date
        
        # Strategia 3: CautÄƒ Ã®n JSON-LD schema
        json_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_scripts:
            try:
                import json
                data = json.loads(script.string)
                
                # FuncÈ›ie helper pentru a cÄƒuta Ã®n structuri nested
                def find_date_modified(obj):
                    if isinstance(obj, dict):
                        if 'dateModified' in obj:
                            return obj['dateModified']
                        for value in obj.values():
                            result = find_date_modified(value)
                            if result:
                                return result
                    elif isinstance(obj, list):
                        for item in obj:
                            result = find_date_modified(item)
                            if result:
                                return result
                    return None
                
                date_modified = find_date_modified(data)
                if date_modified:
                    parsed_date = parse_to_romania_time(date_modified)
                    if parsed_date:
                        return parsed_date
                        
            except:
                continue
        
        print(f"âš ï¸  Nu s-a gÄƒsit data actualizÄƒrii pentru {article_url}")
        return None
        
    except Exception as e:
        print(f"âŒ Eroare extragere datÄƒ actualizare Biziday {article_url}: {e}")
        return None

def extract_updated_date_from_content(url, source_name="unknown"):
    """
    Extrage data actualizÄƒrii dintr-un URL specific Ã®n funcÈ›ie de sursa de È™tiri
    
    Args:
        url: URL-ul articolului
        source_name: Numele sursei ("adevarul", "biziday", etc.)
        
    Returns:
        datetime cu timezone RomÃ¢nia sau None dacÄƒ nu e disponibilÄƒ
    """
    source_name = source_name.lower()
    
    if 'adevarul' in source_name or 'adevarul.ro' in url:
        return extract_adevarul_updated_date(url)
    elif 'biziday' in source_name or 'biziday.ro' in url:
        return extract_biziday_updated_date(url)
    else:
        # Ãncercare genericÄƒ pentru alte surse
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # CautÄƒ meta tags generale pentru datÄƒ modificare
            meta_selectors = [
                'meta[property="article:modified_time"]',
                'meta[name="last-modified"]',
                'meta[name="modified-date"]',
                'meta[property="og:updated_time"]'
            ]
            
            for selector in meta_selectors:
                meta_tag = soup.select_one(selector)
                if meta_tag:
                    content = meta_tag.get('content', '')
                    if content:
                        parsed_date = parse_to_romania_time(content)
                        if parsed_date:
                            return parsed_date
            
            return None
            
        except Exception as e:
            print(f"âŒ Eroare extragere datÄƒ actualizare genericÄƒ {url}: {e}")
            return None

# Test functions
if __name__ == "__main__":
    # Test parsing
    test_dates = [
        "2025-06-29T15:03:11Z",
        "28.06.2025 11:24",
        "Sun, 29 Jun 2025 15:05:19 GMT",
        "2025-06-29 17:26:44"
    ]
    
    print("ğŸ§ª Test parsing date-uri:")
    for date_str in test_dates:
        result = parse_to_romania_time(date_str)
        formatted = format_for_database(result)
        print(f"   '{date_str}' -> {formatted}")
